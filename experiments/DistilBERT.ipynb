{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DistilBertModel, DistilBertConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "inputs = dataset['train']['sentence1'][:15]\n",
    "token_arrays = tokenizer(inputs, truncation=True, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SA_LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SA_LayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_norm(x)\n",
    "\n",
    "class DistilBERT(nn.Module):\n",
    "    def __init__(self, model_name_or_path=\"distilbert-base-uncased\"):\n",
    "        super(DistilBERT, self).__init__()\n",
    "        self.config = DistilBertConfig.from_pretrained(model_name_or_path)\n",
    "        self.distilbert = DistilBertModel.from_pretrained(model_name_or_path, config=self.config)\n",
    "\n",
    "        # Adding SA_LayerNorm head for each transformer layer\n",
    "        self.sa_layer_norms = nn.ModuleList([SA_LayerNorm(self.config.dim) for _ in range(self.config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        embedding_output = hidden_states\n",
    "\n",
    "        k_values, v_values, q_values, out_lin_output, ffn_output, output_layer_norm, sa_layer_norm_output = [], [], [], [], [], [], []\n",
    "        all_hidden_states = [hidden_states]\n",
    "\n",
    "        for i, layer in enumerate(self.distilbert.transformer.layer):\n",
    "            k_values.append(layer.attention.k_lin(hidden_states))\n",
    "            v_values.append(layer.attention.v_lin(hidden_states))\n",
    "            q_values.append(layer.attention.q_lin(hidden_states))\n",
    "\n",
    "            out_lin_output.append(layer.attention.out_lin(hidden_states))\n",
    "\n",
    "            ffn_out = layer.ffn(hidden_states)\n",
    "            ffn_output.append(ffn_out)\n",
    "\n",
    "            hidden_states = layer.output_layer_norm(ffn_out + hidden_states)\n",
    "            output_layer_norm.append(hidden_states)\n",
    "\n",
    "            # Applying SA_LayerNorm to the last hidden state for each transformer layer\n",
    "            sa_layer_norm_output.append(self.sa_layer_norms[i](hidden_states))\n",
    "\n",
    "            all_hidden_states.append(hidden_states)\n",
    "\n",
    "        # Concatenate outputs along dim=0\n",
    "        concatenated_output = torch.cat([\n",
    "            embedding_output,\n",
    "        ], dim=0)\n",
    "\n",
    "        for i in range(len(self.distilbert.transformer.layer)):\n",
    "            concatenated_output = torch.cat([\n",
    "                concatenated_output,\n",
    "                k_values[i],\n",
    "                v_values[i],\n",
    "                q_values[i],\n",
    "                out_lin_output[i],\n",
    "                output_layer_norm[i],\n",
    "                sa_layer_norm_output[i],\n",
    "                ffn_output[i]\n",
    "            ], dim=0)\n",
    "\n",
    "          # Delete variables after use\n",
    "        del k_values[i], v_values[i], q_values[i], out_lin_output[i], output_layer_norm[i], sa_layer_norm_output[i], ffn_output[i], hidden_states\n",
    "\n",
    "        return concatenated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "    model = DistilBERT()\n",
    "    output = model(**token_arrays)\n",
    "    output = output.view(-1, 768*43, 512)\n",
    "    tensor = torch.cat((torch.empty(0), output), dim=1)\n",
    "    tensor = tensor.reshape(33024, len(inputs)*len(token_arrays[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = torch.corrcoef(tensor)\n",
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset\n",
    "del inputs\n",
    "del tensor\n",
    "del tokenizer\n",
    "del token_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "corr = corr.numpy()\n",
    "downsampled_mx = np.zeros((5504, 5504))\n",
    "sub_mx_side = corr.shape[0] // downsampled_mx.shape[0]\n",
    "\n",
    "for i in tqdm(range(downsampled_mx.shape[0])):\n",
    "    row_idxs = slice(sub_mx_side * i, sub_mx_side * (i + 1))\n",
    "    for j in range(downsampled_mx.shape[1]):\n",
    "        col_idxs = slice(sub_mx_side * j, sub_mx_side * (j + 1))\n",
    "        downsampled_mx[i, j] = np.mean(corr[row_idxs, col_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_indices1 = []\n",
    "y_labels1 = []\n",
    "for i in range(0,5504,128):\n",
    "    y_indices1.append(i)\n",
    "    y_labels1.append(i)\n",
    "    \n",
    "plt.figure(figsize=(12, 10))\n",
    "heatmap = sns.heatmap(downsampled_mx, cmap='viridis')\n",
    "\n",
    "plt.title('Downsampled Heatmap with Cluster Labels')\n",
    "plt.xlabel('Column Index')\n",
    "plt.ylabel('Y Values')\n",
    "plt.yticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import fastcluster\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Perform hierarchical clustering with fastcluster\n",
    "linkage_matrix = fastcluster.linkage(downsampled_mx, method='complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "for i in tqdm(range(3,24)):\n",
    "  a = i - 0.5\n",
    "  b = i\n",
    "  threshold = i # Adjust this threshold according to your data\n",
    "  cluster_labels = fcluster(linkage_matrix, a, criterion='distance')\n",
    "  x1.append(a)\n",
    "  y1.append(silhouette_score(downsampled_mx,cluster_labels))\n",
    "  # y1.append(calinski_harabasz_score(downsampled_mx,cluster_labels))\n",
    "  cluster_labels = fcluster(linkage_matrix, b, criterion='distance')\n",
    "  x1.append(b)\n",
    "  # y1.append(calinski_harabasz_score(downsampled_mx,cluster_labels))\n",
    "  y1.append(silhouette_score(downsampled_mx,cluster_labels))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x1, y1)\n",
    "plt.xlabel('Threshold Value')\n",
    "plt.ylabel('silhouette_score - axis')\n",
    "plt.title('silhouette score vs Threshold Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "kneedle = KneeLocator(x1, y1, S = 1000.0, curve = 'concave', direction = 'increasing')\n",
    "threshold = round(kneedle.knee,10)\n",
    "cluster_labels = fcluster(linkage_matrix, threshold, criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map original node indices to their labels or names\n",
    "node_labels = {i: f\"Node_{i}\" for i in range(corr.shape[0])}\n",
    "\n",
    "# Sort the correlation matrix based on the cluster labels\n",
    "sorted_indices = np.argsort(cluster_labels)\n",
    "corr_sorted = downsampled_mx[sorted_indices][:, sorted_indices]\n",
    "\n",
    "# Create a list of original node labels based on the sorted indices\n",
    "sorted_labels = [node_labels[i] for i in sorted_indices]\n",
    "\n",
    "# Find the boundaries between clusters\n",
    "cluster_boundaries = np.where(np.diff(cluster_labels[sorted_indices]) != 0)[0] + 0.5\n",
    "\n",
    "# Plot the heatmap of the sorted correlation matrix with original node labels and cluster boundaries\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(corr_sorted, cmap='coolwarm', aspect='auto')\n",
    "\n",
    "# Add vertical lines to separate clusters\n",
    "for boundary in cluster_boundaries:\n",
    "    ax.axvline(boundary, color='black', linewidth=0.5)\n",
    "\n",
    "# Add horizontal lines to separate clusters\n",
    "for boundary in cluster_boundaries:\n",
    "    ax.axhline(boundary, color='black', linewidth=0.5)\n",
    "\n",
    "# Add cluster indices below the cluster boundaries\n",
    "unique_clusters = np.unique(cluster_labels)\n",
    "cluster_indices = np.arange(len(unique_clusters))\n",
    "cluster_labels_sorted = cluster_labels[sorted_indices]\n",
    "cluster_tick_positions = [np.where(cluster_labels_sorted == cluster)[0][-1] + 0.5 for cluster in unique_clusters]\n",
    "ax.set_xticks(cluster_tick_positions)\n",
    "ax.set_xticklabels(cluster_indices, rotation=90)\n",
    "\n",
    "\n",
    "ax.set_yticks(cluster_tick_positions)\n",
    "ax.set_yticklabels(cluster_indices, rotation=90)\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
