{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puzis/llmnet/blob/main/experiments/Distil_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "7dH4P4_ajcuu"
      },
      "id": "7dH4P4_ajcuu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "afe9f12a-d607-4a22-b2d6-8668dfd36418",
      "metadata": {
        "id": "afe9f12a-d607-4a22-b2d6-8668dfd36418"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, DistilBertModel, DistilBertConfig\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0025d8df-bd2c-4ae3-a026-f0ef2021b82c",
      "metadata": {
        "id": "0025d8df-bd2c-4ae3-a026-f0ef2021b82c"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"glue\", \"mrpc\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "tokens = tokenizer(dataset['train']['sentence1'][:15], truncation=True, padding=\"longest\", return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5324fc04-ad0e-403e-9f60-6318734121ea",
      "metadata": {
        "id": "5324fc04-ad0e-403e-9f60-6318734121ea"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"Amod/mental_health_counseling_conversations\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "tokens = tokenizer(dataset['train']['Response'][:15], truncation=True, padding=\"longest\", return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "748c74bc-5475-4f0b-b155-3de157448cc9",
      "metadata": {
        "id": "748c74bc-5475-4f0b-b155-3de157448cc9"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"tweet_eval\", \"sentiment\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "tokens = tokenizer(dataset['train']['text'][:15], truncation=True, padding=\"max_length\", return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "636e216f-7e95-4d2d-9fc0-d3ffd600cd7c",
      "metadata": {
        "id": "636e216f-7e95-4d2d-9fc0-d3ffd600cd7c"
      },
      "outputs": [],
      "source": [
        "class SA_LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(SA_LayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_norm(x)\n",
        "\n",
        "class DistilBERT(nn.Module):\n",
        "    def __init__(self, model_name_or_path=\"distilbert-base-uncased\"):\n",
        "        super(DistilBERT, self).__init__()\n",
        "        self.config = DistilBertConfig.from_pretrained(model_name_or_path)\n",
        "        self.distilbert = DistilBertModel.from_pretrained(model_name_or_path, config=self.config)\n",
        "\n",
        "        # Adding SA_LayerNorm head for each transformer layer\n",
        "        self.sa_layer_norms = nn.ModuleList([SA_LayerNorm(self.config.dim) for _ in range(self.config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "\n",
        "        embedding_output = hidden_states\n",
        "\n",
        "        k_values, v_values, q_values, out_lin_output, ffn_output, output_layer_norm, sa_layer_norm_output = [], [], [], [], [], [], []\n",
        "        all_hidden_states = [hidden_states]\n",
        "\n",
        "        for i, layer in enumerate(self.distilbert.transformer.layer):\n",
        "            k_values.append(layer.attention.k_lin(hidden_states))\n",
        "            v_values.append(layer.attention.v_lin(hidden_states))\n",
        "            q_values.append(layer.attention.q_lin(hidden_states))\n",
        "\n",
        "            out_lin_output.append(layer.attention.out_lin(hidden_states))\n",
        "\n",
        "            ffn_out = layer.ffn(hidden_states)\n",
        "            ffn_output.append(ffn_out)\n",
        "\n",
        "            hidden_states = layer.output_layer_norm(ffn_out + hidden_states)\n",
        "            output_layer_norm.append(hidden_states)\n",
        "\n",
        "            # Applying SA_LayerNorm to the last hidden state for each transformer layer\n",
        "            sa_layer_norm_output.append(self.sa_layer_norms[i](hidden_states))\n",
        "\n",
        "            all_hidden_states.append(hidden_states)\n",
        "\n",
        "        # Concatenate outputs along dim=0\n",
        "        concatenated_output = torch.cat([\n",
        "            embedding_output,\n",
        "        ], dim=0)\n",
        "\n",
        "        for i in range(len(self.distilbert.transformer.layer)):\n",
        "            concatenated_output = torch.cat([\n",
        "                concatenated_output,\n",
        "                k_values[i],\n",
        "                v_values[i],\n",
        "                q_values[i],\n",
        "                out_lin_output[i],\n",
        "                output_layer_norm[i],\n",
        "                sa_layer_norm_output[i],\n",
        "                ffn_output[i]\n",
        "            ], dim=0)\n",
        "\n",
        "        return concatenated_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model = DistilBERT()\n",
        "  tensor = torch.empty(0)\n",
        "  output = model(**tokens)\n",
        "  output = output.reshape(768*43, len(tokens['input_ids'][1])*15)"
      ],
      "metadata": {
        "id": "uy11otVYoOhr"
      },
      "id": "uy11otVYoOhr",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corrcoef(input):\n",
        "    rowvar = False\n",
        "    dim = 0 if rowvar else 1\n",
        "    tensor = input - input.mean(dim=dim, keepdim=True)\n",
        "    norm = (tensor * tensor).sum(dim=dim, keepdim=True).sqrt()\n",
        "    corr = (tensor @ tensor.t()) / norm / norm.t()\n",
        "    return corr.squeeze()"
      ],
      "metadata": {
        "id": "yL0SbxcmzaMM"
      },
      "id": "yL0SbxcmzaMM",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = corrcoef(output)"
      ],
      "metadata": {
        "id": "Earsk6lkzzWq"
      },
      "id": "Earsk6lkzzWq",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del output"
      ],
      "metadata": {
        "id": "8Xkr4Lqa37m_"
      },
      "id": "8Xkr4Lqa37m_",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56513d3b-1b5b-4915-83aa-923ed54283bc",
      "metadata": {
        "id": "56513d3b-1b5b-4915-83aa-923ed54283bc"
      },
      "outputs": [],
      "source": [
        "plt.imshow(corr.detach().numpy(), cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16646828-ae07-484f-b8a2-a15ba7eaf71d",
      "metadata": {
        "id": "16646828-ae07-484f-b8a2-a15ba7eaf71d"
      },
      "outputs": [],
      "source": [
        "def extract_edges_from_correlation_matrix(correlation_matrix, threshold):\n",
        "    positive_mask = correlation_matrix > threshold\n",
        "    negative_mask = correlation_matrix < -threshold\n",
        "    edge_mask = positive_mask | negative_mask\n",
        "    edges = torch.nonzero(edge_mask, as_tuple=False)\n",
        "    edges = torch.unique(edges, dim=0)\n",
        "\n",
        "    return edges\n",
        "\n",
        "edges = extract_edges_from_correlation_matrix(tensor, threshold=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72cd6fd0-aa4c-4a98-a0b4-778f60c6ea0d",
      "metadata": {
        "id": "72cd6fd0-aa4c-4a98-a0b4-778f60c6ea0d"
      },
      "outputs": [],
      "source": [
        "src_nodes = edges[:, 0]\n",
        "tgt_nodes = edges[:, 1]\n",
        "non_self_loop_indices = src_nodes != tgt_nodes\n",
        "filtered_edge_list = edges[non_self_loop_indices]\n",
        "\n",
        "edges = filtered_edge_list.tolist()\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edges)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}