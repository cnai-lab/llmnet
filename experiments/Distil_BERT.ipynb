{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puzis/llmnet/blob/main/experiments/Distil_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets networkx"
      ],
      "metadata": {
        "id": "7dH4P4_ajcuu"
      },
      "id": "7dH4P4_ajcuu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe9f12a-d607-4a22-b2d6-8668dfd36418",
      "metadata": {
        "id": "afe9f12a-d607-4a22-b2d6-8668dfd36418"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, DistilBertModel, DistilBertConfig\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#distilbert-base-uncased\n",
        "#distilbert-base-uncased-finetuned-sst-2-english\n",
        "#fmops/distilbert-prompt-injection\n",
        "#distilbert-base-multilingual-cased\n",
        "#lvwerra/distilbert-imdb"
      ],
      "metadata": {
        "id": "28LmZmY1vLLR"
      },
      "id": "28LmZmY1vLLR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "#dataset = load_dataset(\"glue\", \"mrpc\")\n",
        "#inputs = dataset['train']['sentence1'][:15]\n",
        "\n",
        "\n",
        "#2\n",
        "#dataset = load_dataset(\"Amod/mental_health_counseling_conversations\")\n",
        "#\n",
        "\n",
        "#3\n",
        "#dataset = load_dataset(\"imdb\")\n",
        "#inputs = dataset['train']['text'][:10]"
      ],
      "metadata": {
        "id": "a_HknCVZvwFz"
      },
      "id": "a_HknCVZvwFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0025d8df-bd2c-4ae3-a026-f0ef2021b82c",
      "metadata": {
        "id": "0025d8df-bd2c-4ae3-a026-f0ef2021b82c"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"glue\", \"mrpc\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "inputs = dataset['train']['sentence1'][:15]\n",
        "token_arrays = tokenizer(inputs, truncation=True, padding=\"max_length\", return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "636e216f-7e95-4d2d-9fc0-d3ffd600cd7c",
      "metadata": {
        "id": "636e216f-7e95-4d2d-9fc0-d3ffd600cd7c"
      },
      "outputs": [],
      "source": [
        "class SA_LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(SA_LayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_norm(x)\n",
        "\n",
        "class DistilBERT(nn.Module):\n",
        "    def __init__(self, model_name_or_path=\"distilbert-base-uncased-finetuned-sst-2-english\"):\n",
        "        super(DistilBERT, self).__init__()\n",
        "        self.config = DistilBertConfig.from_pretrained(model_name_or_path)\n",
        "        self.distilbert = DistilBertModel.from_pretrained(model_name_or_path, config=self.config)\n",
        "\n",
        "        # Adding SA_LayerNorm head for each transformer layer\n",
        "        self.sa_layer_norms = nn.ModuleList([SA_LayerNorm(self.config.dim) for _ in range(self.config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "\n",
        "        embedding_output = hidden_states\n",
        "\n",
        "        k_values, v_values, q_values, out_lin_output, ffn_output, output_layer_norm, sa_layer_norm_output = [], [], [], [], [], [], []\n",
        "        all_hidden_states = [hidden_states]\n",
        "\n",
        "        for i, layer in enumerate(self.distilbert.transformer.layer):\n",
        "            k_values.append(layer.attention.k_lin(hidden_states))\n",
        "            v_values.append(layer.attention.v_lin(hidden_states))\n",
        "            q_values.append(layer.attention.q_lin(hidden_states))\n",
        "\n",
        "            out_lin_output.append(layer.attention.out_lin(hidden_states))\n",
        "\n",
        "            ffn_out = layer.ffn(hidden_states)\n",
        "            ffn_output.append(ffn_out)\n",
        "\n",
        "            hidden_states = layer.output_layer_norm(ffn_out + hidden_states)\n",
        "            output_layer_norm.append(hidden_states)\n",
        "\n",
        "            # Applying SA_LayerNorm to the last hidden state for each transformer layer\n",
        "            sa_layer_norm_output.append(self.sa_layer_norms[i](hidden_states))\n",
        "\n",
        "            all_hidden_states.append(hidden_states)\n",
        "\n",
        "        # Concatenate outputs along dim=0\n",
        "        concatenated_output = torch.cat([\n",
        "            embedding_output,\n",
        "        ], dim=0)\n",
        "\n",
        "        for i in range(len(self.distilbert.transformer.layer)):\n",
        "            concatenated_output = torch.cat([\n",
        "                concatenated_output,\n",
        "                k_values[i],\n",
        "                v_values[i],\n",
        "                q_values[i],\n",
        "                out_lin_output[i],\n",
        "                output_layer_norm[i],\n",
        "                sa_layer_norm_output[i],\n",
        "                ffn_output[i]\n",
        "            ], dim=0)\n",
        "\n",
        "          # Delete variables after use\n",
        "        del k_values[i], v_values[i], q_values[i], out_lin_output[i], output_layer_norm[i], sa_layer_norm_output[i], ffn_output[i], hidden_states\n",
        "\n",
        "\n",
        "        return concatenated_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model = DistilBERT().cuda()\n",
        "    output = model(**token_arrays.to('cuda'))\n",
        "    output = output.view(-1, 768*43, 512)\n",
        "    tensor = torch.cat((torch.empty(0).cuda(), output), dim=1)\n",
        "    tensor = tensor.reshape(33024, len(inputs)*len(token_arrays[1]))\n",
        "    corr = torch.corrcoef(tensor)"
      ],
      "metadata": {
        "id": "uy11otVYoOhr"
      },
      "id": "uy11otVYoOhr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del dataset\n",
        "del inputs\n",
        "del tensor\n",
        "del tokenizer\n",
        "del token_arrays\n",
        "del output\n",
        "del model\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "mOgMv1rj2Aat"
      },
      "id": "mOgMv1rj2Aat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#degree distribution of each node\n",
        "degree_distribution = torch.sum(corr, dim=0)"
      ],
      "metadata": {
        "id": "ajexK8L-XMnD"
      },
      "id": "ajexK8L-XMnD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fraction of node vs degree distribution\n",
        "degree_counts = torch.bincount(degree_distribution[degree_distribution >= 0].int())\n",
        "degree_fractions = degree_counts / degree_distribution.shape[0]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(degree_fractions.cpu())\n",
        "plt.title('Degree Distribution')\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Fraction of Nodes')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vslMVLUzhDSw"
      },
      "id": "vslMVLUzhDSw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#node vs degree distribution\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(degree_distribution.cpu().numpy())\n",
        "plt.title('Linear Node vs Degree Distribution')\n",
        "plt.xlabel('Node')\n",
        "plt.ylabel('Degree')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7zY7Z7GOXwNc"
      },
      "id": "7zY7Z7GOXwNc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#log-log degree distribution\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.loglog(degree_distribution.cpu().numpy())\n",
        "plt.title('Log-Log Node vs Degree Distribution')\n",
        "plt.xlabel('Node')\n",
        "plt.ylabel('Degree')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d1wheS6kZ-hj"
      },
      "id": "d1wheS6kZ-hj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#semi-log degree distribution\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.semilogy(degree_distribution.cpu().numpy())\n",
        "plt.title('Semi-Log Node vs Degree Distribution')\n",
        "plt.xlabel('Node')\n",
        "plt.ylabel('Degree')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9RsJfeX2adhp"
      },
      "id": "9RsJfeX2adhp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_matrix = corr.flatten().cpu().numpy()\n",
        "threshold = np.percentile(flattened_matrix, 95)"
      ],
      "metadata": {
        "id": "K8Q1RlKq56qh"
      },
      "id": "K8Q1RlKq56qh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold"
      ],
      "metadata": {
        "id": "Zy-zU-cU3Cyi"
      },
      "id": "Zy-zU-cU3Cyi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = corr > threshold\n",
        "edges = torch.nonzero(mask, as_tuple=False)\n",
        "edges = torch.unique(edges, dim=0)"
      ],
      "metadata": {
        "id": "LO3zhl4L6X8s"
      },
      "id": "LO3zhl4L6X8s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del flattened_matrix\n",
        "del mask\n",
        "del threshold\n",
        "del corr\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "qdDuz7jI6F1n"
      },
      "id": "qdDuz7jI6F1n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = edges.cpu().numpy()"
      ],
      "metadata": {
        "id": "fQCmxjGQnwRy"
      },
      "id": "fQCmxjGQnwRy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create graph\n",
        "G = nx.Graph()\n",
        "for edge in edges:\n",
        "    G.add_edge(*edge)\n",
        "del edges\n",
        "del edge\n",
        "G.remove_edges_from(nx.selfloop_edges(G))"
      ],
      "metadata": {
        "id": "yNVXcSnPHQVp"
      },
      "id": "yNVXcSnPHQVp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rich club\n",
        "rc = nx.rich_club_coefficient(G, normalized=False, seed=None)\n",
        "degrees = list(rc.keys())\n",
        "coefficients = list(rc.values())\n",
        "plt.plot(degrees, coefficients)\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Rich Club Coefficient')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z2l6EolQHU2e"
      },
      "id": "z2l6EolQHU2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DpEkmV9t3Z21"
      },
      "id": "DpEkmV9t3Z21",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}